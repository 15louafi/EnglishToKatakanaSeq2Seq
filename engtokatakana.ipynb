{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English to Katakana seq2seq model (credit to wanasit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is a .csv file, containing english words on the first column and their translation in katakana in the second column (built by wanasit, see https://wanasit.github.io/english-to-katakana-using-sequence-to-sequence-in-keras.html for more details). We're going to build a model that automatically does the conversion from english to katakana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Embedding, LSTM, TimeDistributed, Dense\n",
    "from keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                           0                1\n",
      "0               Unschooling         アンスクーリング\n",
      "1                  Lovosice           ロヴォシツェ\n",
      "2                     Milch              ミルヒ\n",
      "3                      Juva              ユヴァ\n",
      "4                 Brembilla           ブレンビッラ\n",
      "5                     Sa Pa               サパ\n",
      "6                   Brumano            ブルマーノ\n",
      "7                Brusaporto           ブルザポルト\n",
      "8                  Deventer          デーフェンテル\n",
      "9                  Enschede           エンスヘーデ\n",
      "10                   Tandil            タンディル\n",
      "11               Buckypaper         バッキーペーパー\n",
      "12                Bastiglia          バスティーリア\n",
      "13          Personalization      パーソナライゼーション\n",
      "14               Mandalgovi           マンダルゴビ\n",
      "15                 Bomporto            ボンポルト\n",
      "16            Campogalliano        カンポガッリアーノ\n",
      "17              Haaksbergen         ハークスベルヘン\n",
      "18               Camposanto           カンポサント\n",
      "19      Castelfranco Emilia   カステルフランコ・エミーリア\n",
      "20                   Ferenc            フェレンツ\n",
      "21      Castelnuovo Rangone  カステルヌオーヴォ・ランゴーネ\n",
      "22                  Cavezzo           カヴェッツォ\n",
      "23              Bud Collins          バド・コリンズ\n",
      "24            Bud Greenspan       バド・グリーンスパン\n",
      "25                   Fanano            ファナーノ\n",
      "26            Finale Emilia      フィナーレ・エミーリア\n",
      "27         Fiorano Modenese     フィオラーノ・モデネーゼ\n",
      "28                 Fiumalbo           フィウマルボ\n",
      "29                Formigine          フォルミージネ\n",
      "...                     ...              ...\n",
      "107231              Sarsina             サルシナ\n",
      "107232             Tredozio          トレドーツィオ\n",
      "107233            Buckenhof          ブッケンホーフ\n",
      "107234           Verghereto          ヴェルゲレート\n",
      "107235            Bagnatica          バニャーティカ\n",
      "107236              Barbata            バルバータ\n",
      "107237              Bariano            バリアーノ\n",
      "107238              Barzana            バルザーナ\n",
      "107239             Bedulita           ベドゥリータ\n",
      "107240             Berbenno            ベルベンノ\n",
      "107241             Bianzano          ビアンツァーノ\n",
      "107242               Blello             ブレッロ\n",
      "107243              Bolgare             ボルガレ\n",
      "107244             Boltiere          ボルティエーレ\n",
      "107245         Bonate Sopra         ボナーテ・ソプラ\n",
      "107246        Fender Bronco       フェンダー・ブロンコ\n",
      "107247       Fender Esquire    フェンダー・エスクワイヤー\n",
      "107248          Piha Rescue         ピハ・レスキュー\n",
      "107249          Toyota Park           トヨタパーク\n",
      "107250         Bonate Sotto         ボナーテ・ソット\n",
      "107251              Bossico             ボッシコ\n",
      "107252            Bottanuco           ボッタヌーコ\n",
      "107253               Bracca             ブラッカ\n",
      "107254               Branzi            ブランツィ\n",
      "107255             Brembate           ブレンバーテ\n",
      "107256              Dalfsen            ダルフセン\n",
      "107257            Feprazone           フェプラゾン\n",
      "107258     Buckwheat Zydeco     バックウィート・ザディコ\n",
      "107259         Castaway Cay       キャスタウェイ・ケイ\n",
      "107260             Astatine            アスタチン\n",
      "\n",
      "[107261 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./trainingdata/joined_titles.csv', header=None)\n",
    "print(data.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn this data into a X and Y vectors for training first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [word.lower() for word in data[0]]\n",
    "Y = [word for word in data[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not done yet. Our model only takes numerical data and we cannot input strings directly. We have to build a sort of encoding for each character in english and in katakana, but also store the way to decode the characters so we can read the output of the model at the end. Also remember that a model only takes input with same size, so we have to use padding. Let's use 0 for padding, 1 for start of sequence, and just code all the characters as int based on the order they appeared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "START_CHAR_CODE = 1\n",
    "\n",
    "def encode_characters(words):\n",
    "    count = 2\n",
    "    encoding = {}\n",
    "    decoding = {1: 'START'}\n",
    "    for c in set([char for word in words for char in word]): #gets all the chars of the data set\n",
    "        encoding[c] = count\n",
    "        decoding[count] = c\n",
    "        count += 1\n",
    "    return encoding, decoding, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
